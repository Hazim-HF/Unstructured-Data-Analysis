---
title: "Part 1 - Task 2"
output: html_document
---

```{r}
library(rvest)
library(tidyverse)
```

```{r}
library(rvest)

# Read the HTML file
page <- read_html("https://www.amazon.com/s?k=laptop&page=1")

# Extract product containers
products <- html_nodes(page, ".s-main-slot .s-result-item")

# Extract product title
titles <- products %>% html_node("h2 span") %>% html_text(trim = TRUE)

# Extract product price (whole and fractional)
price_whole <- products %>% html_node(".a-price-whole") %>% html_text(trim = TRUE)
price_fraction <- products %>% html_node(".a-price-fraction") %>% html_text(trim = TRUE)

# Combine the whole and fractional price
prices <- ifelse(!is.na(price_whole), paste0(price_whole, price_fraction), NA)

# Extract product rating
ratings <- products %>% html_node(".a-icon-alt") %>% html_text(trim = TRUE)

# Combine into a data frame
laptop_data <- data.frame(
  Title = titles,
  Price = prices,
  Rating = ratings,
  stringsAsFactors = FALSE
)

print(laptop_data)

```

```{r}
library(rvest)

# Read HTML
page <- read_html("https://www.amazon.com/s?k=laptop&page=1")

# Extract product titles
titles <- products %>% html_node("h2 span") %>% html_text(trim = TRUE)

# Extract prices (whole and fraction)
price_whole <- page %>%
  html_nodes(".a-price-whole") %>%
  html_text()

price_fraction <- page %>%
  html_nodes(".a-price-fraction") %>%
  html_text()

# Combine price whole + fraction
prices <- paste0(price_whole, price_fraction)

# Extract ratings (e.g., 4.5 out of 5 stars)
ratings <- page %>%
  html_nodes("span.a-icon-alt") %>%
  html_text()

# Extract number of reviews
reviews <- page %>%
  html_nodes("span.s-underline-text") %>%
  html_text()

# Clean rating (keep only numerical)
ratings_clean <- gsub(" out of 5 stars", "", ratings)

# Create dataframe
laptop_data <- data.frame(
  Title = titles,
  Price = prices[1:length(titles)],      # Ensure lengths match
  Rating = ratings_clean[1:length(titles)],
  Reviews = reviews[1:length(titles)]
)

# View result
print(head(laptop_data))
```

# Hathim

```{r}
newborn_pages <- paste0("https://www.amazon.com/s?k=newborn+diapers&page=",1:3)
diapers_pages <- paste0("https://www.amazon.com/s?k=diapers&page=",1:3)
```

```{r}
# Function to extract titles from a single page
extract_details <- function(page_url) {
  page <- read_html(page_url)
  
  # Extract product titles using the h2 tag with specific classes
  title_nodes <- html_nodes(page, 'h2.a-size-base-plus.a-spacing-none.a-color-base.a-text-normal span')
  price_nodes <- html_nodes(page, '.a-price-whole')
  delivery_nodes <- html_nodes(page, 'div[data-cy="delivery-recipe"] span.a-text-bold')
  
  # Get the text content
  titles <- html_text(title_nodes)
  prices <- html_text(price_nodes)
  deliveries <- html_text(delivery_nodes)
  
  # Pad shorter vector with NA
  max_len <- max(length(titles), length(prices), length(deliveries))
  length(titles) <- max_len
  length(prices) <- max_len
  length(deliveries) <- max_len
  
  # Combine into dataframe
  df <- data.frame(Title = titles, Price = prices, Deliveries = deliveries,stringsAsFactors = FALSE)
  
  return(df)
}

newborn <- do.call("rbind", lapply(newborn_pages, extract_details))
diapers <- do.call("rbind", lapply(diapers_pages, extract_details))
```

```{r}
newborn_processed <- newborn %>%
  mutate(
    Price = as.numeric(Price),                        
    DeliveryDateParsed = as.Date(                     
      paste(Deliveries, format(Sys.Date(), "%Y")),
      format = "%a, %b %d %Y"
    ),
    DeliveryDuration = as.numeric(DeliveryDateParsed - Sys.Date())
  ) %>%
  drop_na(Title, Price, DeliveryDateParsed) %>%
  select(-Deliveries)

  
newborn_processed 
```

```{r}
mean(newborn_processed$DeliveryDuration)
```

```{r}
diapers_processed <- diapers %>%
  mutate(                    
    Price = as.numeric(Price),                        
    DeliveryDateParsed = as.Date(                     
      paste(Deliveries, format(Sys.Date(), "%Y")),
      format = "%a, %b %d %Y"
    ),
    DeliveryDuration = as.numeric(DeliveryDateParsed - Sys.Date())
  ) %>%
  drop_na(Title, Price, DeliveryDateParsed) %>%
  select(-Deliveries)

diapers_processed
```

```{r}
mean(diapers_processed$DeliveryDuration)
```

```{r}
brands <- c("Huggies", "Pampers", "Mama Bear", "Dyper", "Hello Bello", "Luvs")

# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
  sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})

# 2. Calculate mean price per brand
brand_price <- function(brand) {
  # Extract titles and prices matching the brand
  matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
  brand_prices <- diapers_processed$Price[matching]
  
  # Clean price and convert to numeric
  brand_prices <- as.numeric(gsub(",", "", brand_prices))
  brand_prices <- na.omit(brand_prices)
  
  # Return mean price if available
  if (length(brand_prices) == 0) {
    return(NA)
  } else {
    return(mean(brand_prices))
  }
}

# 3. Combine results into data frame
diapers_df <- data.frame(
  Brand = brands,
  Count = brand_counts,
  Mean_Price = sapply(brands, brand_price),
  stringsAsFactors = FALSE
)

print(diapers_df)
```

```{r}
newborn_brand_counts <- sapply(brands, function(brand) {
  pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
  sum(str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE)))
})

newborn_brand_price <- function(brand) {
  pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
  matching <- str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE))
  brand_prices <- newborn_processed$Price[matching]
  
  brand_prices <- as.numeric(gsub(",", "", brand_prices))
  brand_prices <- na.omit(brand_prices)
  
  if (length(brand_prices) == 0) {
    return(NA)
  } else {
    return(mean(brand_prices))
  }
}

newborn_df <- data.frame(
  Brand = brands,
  Count = newborn_brand_counts,
  Mean_Price = sapply(brands, newborn_brand_price),
  stringsAsFactors = FALSE
)

print(newborn_df)
```

```{r}
library(RSelenium)

# Start Selenium server
rD <- rsDriver(browser = "chrome", port = 4545L, chromever = "latest")
remDr <- rD$client

# Navigate to Fiverr
url <- "https://www.fiverr.com/categories/programming-tech/software-development?source=pagination&filter=rating&page=2"
remDr$navigate(url)

# Get page source after JavaScript renders
page_source <- remDr$getPageSource()[[1]]
library(rvest)
html <- read_html(page_source)

# Now you can use rvest functions to extract elements
titles <- html %>% html_nodes(".gig-info .gig-title") %>% html_text()

# Cleanup
remDr$close()
rD$server$stop()

```
