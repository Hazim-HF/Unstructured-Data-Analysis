---
title: "Unstructured Data Analysis"
author: "HAZIM FITRI"
date: "2025-04-13"
output:
  pdf_document:
    toc: true
    toc_depth: 6
    latex_engine: xelatex
    keep_tex: true
    includes:
     in_header: preamble.tex
geometry: margin=0.5cm
---

DIKW Pyramid (

<h1>hi</h1>

::: {.alert .alert-block .alert-info}
`What is data`{=html}
:::

# Part 1: Extract Text from Files

```{r part1_extract_text_from_files}
eg1<-read.table("Attachment 1/GC.txt",fill=T,header=F) #Data CG.txt
eg1[1,]
eg2<-read.csv("Attachment 1/GC.csv",header=F) #Data GC.csv
eg2[1,]
#Using tm package
library(tm)# text mining
eg3<-c("Hi!","Welcome to STQD6114","Tuesday, 11-1pm")
mytext<-VectorSource(eg3)
mycorpus<-VCorpus(mytext)
inspect(mycorpus)
as.character(mycorpus[[1]])
```

```{r extract_text_from_files}

#Example using VectorSource
eg4<-t(eg1) #From example 1
a<-sapply(1:7,function(x) # 1:7 can be changed into "ncol(eg4)"
  trimws(paste(eg4[,x],collapse=" "),"right"))
mytext<-VectorSource(a)
mycorpus<-VCorpus(mytext)
inspect(mycorpus)
as.character(mycorpus[[1]])

#Example using DirSource
mytext<-DirSource("movies")
mycorpus<-VCorpus(mytext)
inspect(mycorpus)
as.character(mycorpus[[1]])

#Example using DataFrameSource
eg5<-read.csv("Attachment 1/Doc6.csv",header=F) #Using doc6.csv
docs<-data.frame(doc_id=c("doc_1","doc_2"),
                 text=c(as.character(eg5[1,]),
                        as.character(eg5[2,])),
                 dmeta1=1:2,dmeta2=letters[1:2],
                 stringsAsFactors=F)
mytext<-DataframeSource(docs)
mycorpus<-VCorpus(mytext)
inspect(mycorpus)
as.character(mycorpus[[1]])
```

```{r}
eg5b = read.csv("Attachment 1/GC.csv", header=F)

```

# Part 2: Web Scrapping

<a href="https://htmlcheatsheet.com/">[HTML](https://htmlcheatsheet.com/%22%3EHTML) Cheat Sheet</a>

```{r}
eg6<-readLines("https://en.wikipedia.org/wiki/Data_science")
eg6[grep("\\h2",eg6)]
eg6[grep("\\p",eg6)] #paragraph

#Using library XML
library(XML)
doc<-htmlParse(eg6)
doc.text<-unlist(xpathApply(doc,'//p',xmlValue))
unlist(xpathApply(doc,'//h2',xmlValue))

#Using library httr
library(httr)
eg7<-GET("https://www.edureka.co/blog/what-is-data-science/")
doc<-htmlParse(eg7)
doc.text<-unlist(xpathApply(doc,'//p',xmlValue))
```

```{r}
#Using library rvest
library(rvest)
eg8<-read_html("https://www.edureka.co/blog/what-is-data-science/")
nodesh<-html_nodes(eg8,'.col-lg-9 :nth-child(1)')
nodes<-html_nodes(eg8,'.color-4a div span , .btn-become-profesional-link+ p')
texts<-html_text(nodes)
#Selecting multiple pages
pages<-paste0('https://www.amazon.co.jp/s?k=skincare&crid=28HIW1TYLV9UM&sprefix=skincare%2Caps%2C268&ref=nb_sb_noss_1&page=',0:9)
pages<-paste0('https://www.amazon.com/s?k=condominium&crid=1ZNT0FW4JKRC3&sprefix=condominiu%2Caps%2C312&ref=nb_sb_noss_2&page=',0:2) 
# &page= 
# read the first 3 pages
eg10<-read_html(pages[1])
nodes<-html_nodes(eg10,'.a-price-whole')
texts<-html_text(nodes)
Price<-function(page){
  url<-read_html(page)
  nodes<-html_nodes(url ,'.a-price-whole ')
  html_text(nodes)}
sapply(pages,Price)
do.call("c",lapply(pages,Price))
```
